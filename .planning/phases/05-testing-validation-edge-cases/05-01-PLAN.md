---
phase: 05-testing-validation-edge-cases
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - test/integration-delegation.test.sh
autonomous: true

must_haves:
  truths:
    - "Integration tests pass: Python task with python-pro installed delegates correctly"
    - "Integration tests pass: Same Python task without python-pro executes directly"
    - "Integration tests pass: Mixed-domain plan (5 tasks, different specialists) routes correctly"
    - "Integration tests pass: Existing v1.20 workflows work identically with use_specialists=false"
    - "Integration tests pass: System works correctly with zero VoltAgent specialists installed"
    - "Integration tests pass: Specialist outputs parse correctly in gsd-result-adapter"
  artifacts:
    - path: "test/integration-delegation.test.sh"
      provides: "Integration test suite for delegation workflows"
      min_lines: 800
      exports: ["test_delegation_flow_end_to_end", "test_fallback_specialist_unavailable", "test_backward_compatibility_v120", "test_mixed_domain_plan_routing", "test_zero_specialists_installed", "mock_specialist"]
  key_links:
    - from: "test/integration-delegation.test.sh"
      to: "agents/gsd-executor.md"
      via: "eval function extraction pattern"
      pattern: 'eval "\$\(sed -n.*agents/gsd-executor.md'
    - from: "test/integration-delegation.test.sh"
      to: "mock_specialist()"
      via: "simulates specialist responses for automated testing"
      pattern: "mock_specialist.*python-pro.*typescript-pro"
    - from: "test/integration-delegation.test.sh"
      to: "assert_eq/assert_contains/assert_gt"
      via: "test assertion helpers from existing test suites"
      pattern: "assert_eq|assert_contains|assert_gt"
---

<objective>
Create comprehensive integration test suite validating end-to-end delegation workflows, fallback scenarios, and backward compatibility

Purpose: Validate v1.21 delegation system works correctly across all success criteria defined in Phase 5 roadmap (6 integration test scenarios)
Output: test/integration-delegation.test.sh with 60-80 tests covering delegation flows, fallback handling, mixed-domain routing, v1.20 compatibility, zero-specialist operation
</objective>

<execution_context>
@/Users/matte/Documents/workspace/get-shit-done/.claude/get-shit-done/workflows/execute-plan.md
@/Users/matte/Documents/workspace/get-shit-done/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/Users/matte/Documents/workspace/get-shit-done/.planning/PROJECT.md
@/Users/matte/Documents/workspace/get-shit-done/.planning/ROADMAP.md
@/Users/matte/Documents/workspace/get-shit-done/.planning/STATE.md
@/Users/matte/Documents/workspace/get-shit-done/.planning/REQUIREMENTS.md
@/Users/matte/Documents/workspace/get-shit-done/.planning/phases/05-testing-validation-edge-cases/05-RESEARCH.md

# Existing test patterns to replicate
@/Users/matte/Documents/workspace/get-shit-done/test/foundation-detection.test.sh
@/Users/matte/Documents/workspace/get-shit-done/test/adapter-context.test.sh

# Functions to extract and test
@/Users/matte/Documents/workspace/get-shit-done/agents/gsd-executor.md
</context>

<tasks>

<task type="auto">
  <name>Create integration test suite structure and mock specialist functions</name>
  <files>test/integration-delegation.test.sh</files>
  <action>
Create test/integration-delegation.test.sh following existing GSD test patterns (foundation-detection.test.sh, adapter-context.test.sh).

**Test suite structure:**
1. Header with usage instructions and set +e (don't exit on first error)
2. Color definitions (RED, GREEN, YELLOW, NC)
3. Test counters (TESTS_RUN, TESTS_PASSED, TESTS_FAILED, FAILED_TESTS array)
4. Test helpers: assert_eq(), assert_contains(), assert_not_contains(), assert_gt() - IDENTICAL to existing test suites
5. Function extraction pattern from gsd-executor.md using eval with sed (extract detect_specialist_for_task, make_routing_decision, gsd_task_adapter, gsd_result_adapter, validate_adapter_result)
6. Mock specialist functions for automated testing (no real Claude API calls)

**Mock specialist function structure:**
```bash
mock_specialist() {
  local specialist_type="$1"
  local task_prompt="$2"

  case "$specialist_type" in
    python-pro)
      cat <<'EOF'
```json
{
  "files_modified": ["src/main.py", "tests/test_main.py"],
  "verification_status": "passed",
  "commit_message": "feat(api): implement FastAPI endpoint",
  "deviations": [
    {
      "rule": "Rule 2 - Missing Critical",
      "description": "Added input validation",
      "fix": "Added Pydantic validator"
    }
  ]
}
```
EOF
      ;;
    typescript-pro)
      cat <<'EOF'
```json
{
  "files_modified": ["src/Auth.tsx", "src/types/user.ts"],
  "verification_status": "passed",
  "commit_message": "feat(ui): add authentication component"
}
```
EOF
      ;;
    kubernetes-specialist)
      cat <<'EOF'
```json
{
  "files_modified": ["k8s/deployment.yaml", "k8s/service.yaml"],
  "verification_status": "passed",
  "commit_message": "feat(infra): deploy to Kubernetes cluster"
}
```
EOF
      ;;
    *)
      echo '{"files_modified": [], "verification_status": "unknown", "commit_message": "feat: complete task"}'
      ;;
  esac
}
```

**Important:**
- Use bash-native testing (NO BATS, ShellSpec, or external frameworks)
- Follow EXACT pattern from existing test suites (assert helpers, eval extraction, test counters)
- Mock specialists return structured JSON in markdown code blocks (matching real specialist output format)
- Include main() runner function with test summary output
  </action>
  <verify>bash test/integration-delegation.test.sh shows test suite header, helper functions exist, mock_specialist() returns valid JSON for python-pro/typescript-pro/kubernetes-specialist</verify>
  <done>Test suite file exists with structure matching existing test patterns, mock specialist functions return realistic output, helpers defined</done>
</task>

<task type="auto">
  <name>Implement delegation workflow and fallback scenario tests</name>
  <files>test/integration-delegation.test.sh</files>
  <action>
Add integration test functions covering delegation workflows and fallback scenarios. Each test validates end-to-end behavior from routing decision through adapter processing.

**Test category 1: Delegation workflow (SUCCESS CRITERIA 1)**
- test_delegation_flow_end_to_end() - Python task with python-pro available, routes correctly, adapter generates prompt, mock specialist executes, result adapter parses output
- test_delegation_with_deviations() - Specialist returns deviations array, result adapter extracts them correctly
- test_delegation_verification_passed() - Specialist returns verification_status=passed, correctly parsed
- test_delegation_verification_failed() - Specialist returns verification_status=failed, correctly handled
- test_delegation_files_modified_extraction() - Files array extracted from specialist output using jq

**Test category 2: Fallback scenarios (SUCCESS CRITERIA 2, 5)**
- test_fallback_specialist_unavailable() - Python task but python-pro NOT in AVAILABLE_SPECIALISTS, routes to direct execution with reason "specialist_unavailable"
- test_fallback_parsing_failure() - Specialist returns garbage/unparsable output, result adapter uses fallback values (expected files)
- test_fallback_adapter_error() - Adapter receives malformed input, graceful error handling without crashes
- test_fallback_feature_disabled() - use_specialists=false, all tasks route to direct execution regardless of specialist availability
- test_zero_specialists_installed() - AVAILABLE_SPECIALISTS="" (empty), system works without errors, all tasks direct execution

**Test implementation pattern:**
```bash
test_delegation_flow_end_to_end() {
  echo ""
  echo -e "${YELLOW}=== Integration: Full Delegation Flow ===${NC}"

  # Setup
  USE_SPECIALISTS="true"
  AVAILABLE_SPECIALISTS="python-pro"

  TASK_DESC="Implement Python FastAPI authentication endpoint"
  TASK_FILES="auth.py models.py routes.py tests.py"

  # Step 1: Routing decision
  ROUTE=$(make_routing_decision "$TASK_DESC" "$TASK_FILES" "auto" 2>/dev/null)
  assert_contains "$ROUTE" "delegate:python-pro" "Routes to python-pro specialist"

  # Step 2: Task adapter generates prompt
  PROMPT=$(gsd_task_adapter "Auth task" "$TASK_FILES" "$TASK_DESC" "pytest" "All tests pass" "python-pro")
  assert_contains "$PROMPT" "GSD Execution Rules" "Adapter injects GSD rules"

  # Step 3: Mock specialist execution
  OUTPUT=$(mock_specialist "python-pro" "$PROMPT")

  # Step 4: Result adapter parses output
  RESULT=$(gsd_result_adapter "$OUTPUT" "$TASK_FILES")
  validate_adapter_result "$RESULT"
  assert_eq 0 $? "Result adapter produces valid output"

  # Step 5: Verify fields extracted
  FILES=$(echo "$RESULT" | jq -r '.files_modified[]' 2>/dev/null)
  assert_contains "$FILES" "src/main.py" "Files extracted from specialist output"
}
```

**Important:**
- Each test is self-contained with setup, execution, verification
- Use 2>/dev/null to suppress stderr in routing decisions (expected warnings)
- Validate adapter output with validate_adapter_result() before extracting fields
- Test both happy path AND failure modes (parsing errors, unavailable specialists)
  </action>
  <verify>bash test/integration-delegation.test.sh runs delegation workflow tests and fallback scenario tests, all assertions pass, test output shows passed/failed counts</verify>
  <done>10+ tests covering delegation workflows and fallback scenarios, SUCCESS CRITERIA 1, 2, 5 validated through automated tests</done>
</task>

<task type="auto">
  <name>Implement backward compatibility, mixed-domain routing, and specialist output validation tests</name>
  <files>test/integration-delegation.test.sh</files>
  <action>
Add integration test functions covering backward compatibility, mixed-domain routing, and specialist output validation.

**Test category 3: Backward compatibility (SUCCESS CRITERIA 4)**
- test_v120_execution_flow_unchanged() - use_specialists=false, routing always returns direct execution
- test_v120_specialist_detection_ignored() - Specialists detected but routing ignores them when feature disabled
- test_v120_state_file_format_unchanged() - SUMMARY.md has no specialist-usage frontmatter when delegation disabled
- test_v120_config_with_new_fields() - config.json with voltagent section parses correctly, v1.20 code paths unaffected
- test_v120_commit_format_unchanged() - No co-authorship trailers when delegation disabled

**Test category 4: Mixed-domain routing (SUCCESS CRITERIA 3)**
- test_mixed_domain_plan_routing() - Plan with 5 tasks (Python, TypeScript, docs, Kubernetes, TypeScript tests), each routes correctly
- test_mixed_domain_delegation_counts() - Mixed plan produces both delegated and direct execution tasks
- test_mixed_domain_specialist_variety() - Different specialists used in same plan (python-pro, typescript-pro, kubernetes-specialist)

**Test category 5: Specialist output validation (SUCCESS CRITERIA 6)**
- test_specialist_output_json_structure() - Mock specialist output has required fields (files_modified, verification_status, commit_message)
- test_specialist_output_deviations_optional() - Output with and without deviations both parse correctly
- test_specialist_output_markdown_wrapped() - JSON in markdown code blocks extracts correctly
- test_result_adapter_schema_validation() - validate_adapter_result() catches missing required fields

**Mixed-domain test implementation:**
```bash
test_mixed_domain_plan_routing() {
  echo ""
  echo -e "${YELLOW}=== Integration: Mixed-Domain Plan Routing ===${NC}"

  USE_SPECIALISTS="true"
  AVAILABLE_SPECIALISTS="python-pro typescript-pro kubernetes-specialist"

  # Simulate 5-task plan with different domains
  declare -a TASKS=(
    "Implement Python FastAPI backend:auth.py models.py routes.py:python-pro"
    "Create React frontend component:components/Auth.tsx:typescript-pro"
    "Update README documentation:README.md:none"
    "Deploy to Kubernetes cluster:k8s/deployment.yaml k8s/service.yaml:kubernetes-specialist"
    "Add integration tests:tests/integration.ts:typescript-pro"
  )

  local delegated_count=0
  local direct_count=0

  for task in "${TASKS[@]}"; do
    IFS=":" read -r desc files expected <<< "$task"

    ROUTE=$(make_routing_decision "$desc" "$files" "auto" 2>/dev/null)
    ROUTE_ACTION=$(echo "$ROUTE" | cut -d: -f1)

    if [ "$ROUTE_ACTION" = "delegate" ]; then
      delegated_count=$((delegated_count + 1))
      SPECIALIST=$(echo "$ROUTE" | cut -d: -f2)

      if [ "$expected" != "none" ]; then
        assert_eq "$expected" "$SPECIALIST" "Task routed to correct specialist: $expected"
      fi
    else
      direct_count=$((direct_count + 1))
    fi
  done

  assert_gt "$delegated_count" 0 "Some tasks delegated to specialists"
  assert_gt "$direct_count" 0 "Some tasks executed directly"

  echo -e "${GREEN}âœ“${NC} Mixed-domain plan routes correctly ($delegated_count delegated, $direct_count direct)"
}
```

**Backward compatibility test pattern:**
```bash
test_v120_execution_flow_unchanged() {
  echo ""
  echo -e "${YELLOW}=== Backward Compatibility: v1.20 Execution Flow ===${NC}"

  USE_SPECIALISTS="false"
  AVAILABLE_SPECIALISTS="python-pro typescript-pro"

  TASK_DESC="Add authentication middleware"
  TASK_FILES="middleware/auth.ts"

  ROUTE=$(make_routing_decision "$TASK_DESC" "$TASK_FILES" "auto" 2>/dev/null)
  assert_contains "$ROUTE" "direct:" "v1.20 mode routes to direct execution"
  assert_contains "$ROUTE" "specialists_disabled" "Reason indicates feature disabled"
}
```

**Important:**
- Backward compatibility tests CRITICAL - existing users depend on v1.20 behavior
- Mixed-domain tests validate real-world scenario (plans with multiple specialists)
- Specialist output validation ensures parsing robustness
- Add main() function at end to call ALL test functions and print summary
  </action>
  <verify>bash test/integration-delegation.test.sh runs all test categories, test summary shows 60-80 tests total, all 6 success criteria validated</verify>
  <done>Integration test suite complete with 60-80 tests covering all Phase 5 success criteria, test summary shows pass/fail counts, exit code 0 if all pass</done>
</task>

</tasks>

<verification>
Run integration test suite:
```bash
bash test/integration-delegation.test.sh
```

Expected output:
- Test suite header with Phase 5 title
- Sections for each test category (delegation workflow, fallback, backward compatibility, mixed-domain, specialist output)
- Test summary showing 60-80 tests run
- All tests pass (green checkmarks)
- Exit code 0

Verify test coverage against success criteria:
```bash
# SUCCESS CRITERIA 1: Python task with python-pro delegates correctly
grep -A5 "test_delegation_flow_end_to_end" test/integration-delegation.test.sh

# SUCCESS CRITERIA 2: Same task without python-pro executes directly
grep -A5 "test_fallback_specialist_unavailable" test/integration-delegation.test.sh

# SUCCESS CRITERIA 3: Mixed-domain plan routes correctly
grep -A5 "test_mixed_domain_plan_routing" test/integration-delegation.test.sh

# SUCCESS CRITERIA 4: v1.20 workflows work identically with use_specialists=false
grep -A5 "test_v120_execution_flow_unchanged" test/integration-delegation.test.sh

# SUCCESS CRITERIA 5: Zero specialists installed works correctly
grep -A5 "test_zero_specialists_installed" test/integration-delegation.test.sh

# SUCCESS CRITERIA 6: Specialist outputs parse correctly
grep -A5 "test_specialist_output_json_structure" test/integration-delegation.test.sh
```

All 6 success criteria must have corresponding test functions.
</verification>

<success_criteria>
- [ ] test/integration-delegation.test.sh exists with 60-80 tests
- [ ] Test suite follows existing GSD test patterns (assert helpers, eval extraction, bash-native)
- [ ] Mock specialist functions return realistic JSON output for python-pro, typescript-pro, kubernetes-specialist
- [ ] All 6 Phase 5 success criteria have corresponding test functions
- [ ] bash test/integration-delegation.test.sh exits with code 0 (all tests pass)
- [ ] Test summary shows breakdown by category (delegation workflow, fallback, backward compatibility, mixed-domain, specialist output)
</success_criteria>

<output>
After completion, create `.planning/phases/05-testing-validation-edge-cases/05-01-SUMMARY.md`
</output>
